{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1evYL5amZbACyYutoArw1trhtOPj7jxEc","authorship_tag":"ABX9TyNHB+krGkiggTvpHdKioq3a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-h8SsXETeYp","executionInfo":{"status":"ok","timestamp":1661636323920,"user_tz":240,"elapsed":3269,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"}},"outputId":"6cb1573f-002b-4632-f1b2-07184adedb72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"execute_result","data":{"text/plain":["AlexNet_Exact(\n","  (relu): ReLU(inplace=True)\n","  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","  (conv2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (linear1): Linear(in_features=9216, out_features=1024, bias=True)\n","  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n","  (linear3): Linear(in_features=1024, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":35}],"source":["\n","# !pip install foolbox\n","# import foolbox as fb\n","from google.colab import files\n","\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from datetime import datetime \n","from tqdm.notebook import tqdm \n","import statistics\n","from math import log10\n","import struct\n","from random import randrange\n","import multiprocessing\n","import concurrent.futures\n","import time\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n","from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","import joblib \n","\n","# parameters\n","RANDOM_SEED = 42\n","BATCH_SIZE = 100\n","# N_EPOCHS = 1575\n","IMG_SIZE = 32\n","N_CLASSES = 10\n","\n","# LEARNING_RATE = 0.001\n","# MOMENTUM = 0.9\n","# WEIGHT_DECAY = 1e-3\n","\n","\n","transforms = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","\n","# download and create datasets\n","train_dataset = datasets.CIFAR10(root='cifar10_data', train=True, transform=transforms, download=True)\n","\n","valid_dataset = datasets.CIFAR10(root='cifar10_data', train=False, transform=transforms, download=True)\n","\n","# define the data loaders\n","train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","#Class labels\n","classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n","\n","\n","#implementing AlexNet_Exact model\n","class AlexNet_Exact(nn.Module):\n","\n","    def __init__(self):\n","        super(AlexNet_Exact, self).__init__()        \n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(2,2))\n","        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=(3,3), stride=(1,1), padding=(2,2))\n","        self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","                \n","        self.dropout = nn.Dropout()\n","        self.linear1 = nn.Linear(in_features = 256 * 6 * 6, out_features = 1024)\n","        self.linear2 = nn.Linear(in_features = 1024, out_features = 1024)\n","        self.linear3 = nn.Linear(in_features = 1024, out_features = 10)\n","        \n","        \n","    def forward(self, x):\n","        # Feature extractor\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","\n","        x = self.conv3(x)\n","        x = self.relu(x)\n","\n","        x = self.conv4(x)\n","        x = self.relu(x)\n","\n","        x = self.conv5(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        \n","        x = self.avgpool(x)\n","        \n","        x = x.view(x.size(0), 256 * 6 * 6)\n","        \n","        x = self.dropout(x)\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        \n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        x = self.relu(x)\n","        \n","        logits = self.linear3(x)\n","#         probs = F.softmax(logits, dim=1)\n","        \n","        return logits\n","\n","\n","\n","torch.manual_seed(RANDOM_SEED)\n","target_model = AlexNet_Exact()\n","\n","model_path = '../dataset/Cifar10.pth'\n","target_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","target_model.eval()\n","\n"]},{"cell_type":"code","source":["#Testing Accuracy\n","def get_accuracy(model, data_loader):\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in data_loader:\n","          images, labels = data[0], data[1]\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy = (correct / total)\n","  return accuracy\n","\n","valid_acc = get_accuracy(target_model, valid_loader)\n","print(f'Test_acc:', valid_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KfuqW5Lm1g8","executionInfo":{"status":"ok","timestamp":1661609056584,"user_tz":240,"elapsed":74197,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"}},"outputId":"7be54110-c085-4ea3-c16c-c4f4cd121c88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["valid_acc: 0.8274\n"]}]},{"cell_type":"code","source":["'''\n","Attacker train\n","'''\n","input_mem = []\n","label_mem = []\n","label_cifar10_mem = []\n","\n","with torch.no_grad():\n","  target_model.eval()\n","  for i, data in enumerate(train_loader, 0):\n","    image, label = data[0], data[1]\n","    #batch size 100; so, member = 50*100 = 5000\n","    if i<50:\n","      label_cifar10_mem.append(label)   \n","      logit = target_model(image)\n","      input_mem.append(logit)\n","      label_mem = label_mem + [1 for i in range(BATCH_SIZE)]\n","    \n","\n","input_nonmem = []\n","label_nonmem = []\n","label_cifar10_nonmem = []\n","\n","\n","with torch.no_grad():\n","  target_model.eval()\n","  for i, data in enumerate(valid_loader, 0):\n","    image, label = data[0], data[1]\n","    #batch size 100; so, member = 50*100 = 5000\n","    if i<50:  \n","      label_cifar10_nonmem.append(label)  \n","      logit = target_model(image) #logit is tensor here\n","      input_nonmem.append(logit)\n","      label_nonmem = label_nonmem + [0 for i in range(BATCH_SIZE)]\n","\n","\n","label_cifar10_mem_nonmem = label_cifar10_mem + label_cifar10_nonmem\n","y_cifar10_train = torch.cat(label_cifar10_mem_nonmem, dim=0)\n","\n","input_mem_nonmem = input_mem + input_nonmem\n","X_train_mem_nonmem = torch.cat(input_mem_nonmem, dim=0)\n","# print(X_train_mem_nonmem.size())\n","label_mem_nonmem = label_mem + label_nonmem\n","y_train_attacker_np = np.array(label_mem_nonmem)\n","\n"],"metadata":{"id":"QYjOhpxgarRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Attacker test\n","'''\n","\n","input_mem = []\n","label_mem = []\n","label_cifar10_mem = []\n","\n","with torch.no_grad():\n","  target_model.eval()\n","  for i, data in enumerate(train_loader, 0):\n","    image, label = data[0], data[1]\n","    #batch size 100; so, member = 50*100 = 5000\n","    if i>=50 and i<100: \n","      label_cifar10_mem.append(label) \n","      logit = target_model(image)\n","      input_mem.append(logit)\n","      label_mem = label_mem + [1 for i in range(BATCH_SIZE)]\n","      \n","    \n","\n","\n","input_nonmem = []\n","label_nonmem = []\n","label_cifar10_nonmem = []\n","\n","with torch.no_grad():\n","  target_model.eval()\n","  for i, data in enumerate(valid_loader, 0):\n","    image, label = data[0], data[1]\n","    #batch size 100; so, member = 50*100 = 5000\n","    if i>=50 and i<100:\n","      label_cifar10_nonmem.append(label)  \n","      logit = target_model(image) #logit is tensor here\n","      input_nonmem.append(logit)\n","      label_nonmem = label_nonmem + [0 for i in range(BATCH_SIZE)]\n","    \n","\n","label_cifar10_mem_nonmem = label_cifar10_mem + label_cifar10_nonmem\n","y_cifar10_test = torch.cat(label_cifar10_mem_nonmem, dim=0)\n","\n","input_mem_nonmem = input_mem + input_nonmem\n","X_test_mem_nonmem = torch.cat(input_mem_nonmem, dim=0)\n","# print(X_mem_nonmem.size())\n","y_attacker =  np.array(label_mem_nonmem)\n","label_mem_nonmem = label_mem + label_nonmem\n","y_test_attacker_np = np.array(label_mem_nonmem)\n"],"metadata":{"id":"VmIluX1IpIcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OXTAtzhP-4C5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","I_nn MIA. logit+prob\n","'''\n","\n","logit = X_train_mem_nonmem\n","df_logit = pd.DataFrame(logit.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","df_logit  = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","X_mem_nonmem_prob = torch.sigmoid(logit)\n","# X_mem_nonmem_prob = torch.softmax(logit, dim=-1)\n","df_prob = pd.DataFrame(X_mem_nonmem_prob.detach().numpy())\n","X_train_attacker_df = pd.concat([df_logit, df_prob], axis=1, ignore_index=True)\n","\n","#=============== Attacker Training ==================\n","n_feature = len(X_train_attacker_df.columns) \n","attacker_mlp_logit_prob = MLPClassifier(hidden_layer_sizes=(n_feature, 100, 100, 50), activation='relu', max_iter = 3000, random_state = 1)\n","attacker_mlp_logit_prob.fit(X_train_attacker_df, y_train_attacker_np)\n","X_attacker = pd.concat([df_logit, df_prob], axis=1, ignore_index=True)\n","\n","# y_pred_np = attacker_mlp_logit_prob.predict(X_train_attacker_df)\n","# accuracy  = round(np.mean(y_pred_np == y_train_attacker_np), 2)\n","# print(f'MIA train accuracy: {accuracy}')\n","\n","\n","\n","model_file = '../dataset/cifar10_attacker_mlp_logit_prob.pkl'\n","joblib.dump(attacker_mlp_logit_prob, model_file)\n","attacker_mlp_logit_prob = joblib.load(model_file)\n","\n","#=============== Attacker Testing ==================\n","logit = X_test_mem_nonmem\n","df_logit = pd.DataFrame(logit.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","df_logit  = pd.DataFrame(scaler.fit_transform(df_logit))\n","X_mem_nonmem_prob = torch.sigmoid(logit)\n","df_prob = pd.DataFrame(X_mem_nonmem_prob.detach().numpy())\n","X_test_attacker_df = pd.concat([df_logit, df_prob], axis=1, ignore_index=True)\n","\n","\n","y_pred_np = attacker_mlp_logit_prob.predict(X_attacker)\n","accuracy  = round(np.mean(y_pred_np == y_attacker), 2)\n","print(f'I_nn MIA: {accuracy}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ey1nI67-Snp","executionInfo":{"status":"ok","timestamp":1661652045393,"user_tz":240,"elapsed":58476,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"}},"outputId":"07965647-5bcd-4486-fab9-2b426209d91d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I_nn MIA: 0.91\n"]}]},{"cell_type":"code","source":["'''\n","I_bb MIA\n","'''\n","df_logit = pd.DataFrame(X_train_mem_nonmem.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","X_train_attacker_df  = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","\n","#=============== Attacker Training ==================\n","n_feature = len(X_train_attacker_df.columns) \n","attacker_mlp_logit = MLPClassifier(hidden_layer_sizes=(n_feature, 100, 100, 50), activation='relu', max_iter = 3000, random_state = 1)\n","attacker_mlp_logit.fit(X_train_attacker_df, y_train_attacker_np)\n","X_attacker = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","# y_pred_np = attacker_mlp_logit.predict(X_train_attacker_df)\n","# accuracy  = round(np.mean(y_pred_np == y_train_attacker_np), 2)\n","# print(f'MIA train accuracy: {accuracy}')\n","\n","\n","model_file = '../dataset/cifar10_attacker_mlp_logit.pkl'\n","joblib.dump(attacker_mlp_logit, model_file)\n","attacker_mlp_logit = joblib.load(model_file)\n","\n","#=============== Attacker Testing ==================\n","df_logit = pd.DataFrame(X_test_mem_nonmem.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","X_test_attacker_df  = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","\n","y_pred_np = attacker_mlp_logit.predict(X_attacker)\n","accuracy  = round(np.mean(y_pred_np == y_attacker), 2)\n","print(f'I_bb MIA: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5q4TNQKviZuG","executionInfo":{"status":"ok","timestamp":1661651894847,"user_tz":240,"elapsed":107003,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"}},"outputId":"28178e63-3b12-4f99-cf82-a58df78f59d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I_bb MIA: 0.89\n"]}]},{"cell_type":"code","source":["'''\n","I_bl MIA \n","'''\n","\n","def myCustomLoss(my_outputs, my_labels):\n","    #specifying the batch size\n","    my_batch_size = my_outputs.size()[0] \n","    #calculating the log of softmax values           \n","    my_outputs = F.log_softmax(my_outputs, dim=1)  \n","    #selecting the values that correspond to labels\n","    my_outputs = my_outputs[range(my_batch_size), my_labels] \n","    #returning the results\n","    return my_outputs\n","\n","\n","logit = X_train_mem_nonmem\n","df_logit = pd.DataFrame(logit.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","df_logit  = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","X_mem_nonmem_prob = torch.sigmoid(logit)\n","# X_mem_nonmem_prob = torch.softmax(logit, dim=-1)\n","df_prob = pd.DataFrame(X_mem_nonmem_prob.detach().numpy())\n","\n","loss = myCustomLoss(logit, y_cifar10_train)\n","df_loss = pd.DataFrame(loss.detach().numpy())\n","# scaler = StandardScaler() #94 70\n","scaler = RobustScaler() #94 70\n","df_loss  = pd.DataFrame(scaler.fit_transform(df_loss))\n","\n","X_train_attacker_df = pd.concat([df_logit, df_prob, df_loss], axis=1, ignore_index=True)\n","\n","\n","#=============== Attacker Training ==================\n","n_feature = len(X_train_attacker_df.columns) \n","attacker_mlp_logit_prob_loss = MLPClassifier(hidden_layer_sizes=(n_feature, 100, 100, 25), activation='relu', max_iter = 3000, random_state = 1)\n","attacker_mlp_logit_prob_loss.fit(X_train_attacker_df, y_train_attacker_np)\n","X_attacker = pd.concat([df_logit, df_prob, df_loss], axis=1, ignore_index=True)\n","\n","# y_pred_np = attacker_mlp_logit_prob_loss.predict(X_train_attacker_df)\n","# accuracy  = round(np.mean(y_pred_np == y_train_attacker_np), 2)\n","# print(f'MIA train accuracy: {accuracy}')\n","\n","\n","model_file = '../dataset/cifar10_attacker_mlp_logit_prob_loss.pkl'\n","joblib.dump(attacker_mlp_logit_prob_loss, model_file)\n","attacker_mlp_logit_prob_loss = joblib.load(model_file)\n","\n","\n","#=============== Attacker Testing ==================\n","logit = X_test_mem_nonmem\n","df_logit = pd.DataFrame(logit.detach().numpy())\n","scaler = StandardScaler() #94 70\n","# scaler = RobustScaler() #94 70\n","df_logit  = pd.DataFrame(scaler.fit_transform(df_logit))\n","\n","X_mem_nonmem_prob = torch.sigmoid(logit)\n","# X_mem_nonmem_prob = torch.softmax(logit, dim=-1)\n","df_prob = pd.DataFrame(X_mem_nonmem_prob.detach().numpy())\n","\n","loss = myCustomLoss(logit, y_cifar10_test)\n","df_loss = pd.DataFrame(loss.detach().numpy())\n","# scaler = StandardScaler() #94 70\n","scaler = RobustScaler() #94 70\n","df_loss  = pd.DataFrame(scaler.fit_transform(df_loss))\n","\n","X_test_attacker_df = pd.concat([df_logit, df_prob, df_loss], axis=1, ignore_index=True)\n","\n","# y_pred_np = attacker_mlp_logit_prob_loss.predict(X_test_attacker_df)\n","# accuracy  = round(np.mean(y_pred_np == y_test_attacker_np), 2)\n","# print(f'MIA test accuracy: {accuracy}')\n","\n","y_pred_np = attacker_mlp_logit_prob_loss.predict(X_attacker)\n","accuracy  = round(np.mean(y_pred_np == y_attacker), 2)\n","print(f'I_bl MIA: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wsSGxb5WYtz","executionInfo":{"status":"ok","timestamp":1661652121183,"user_tz":240,"elapsed":58002,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"}},"outputId":"22b00361-ad6a-4114-a9a9-42291af4f490"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I_bl MIA: 0.91\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8qjP26Ay8wD4"},"execution_count":null,"outputs":[]}]}