{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQXFRV+sz9gPE+EW4OC8gU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-rJOQaAqDsL6"},"outputs":[],"source":["!pip install adversarial-robustness-toolbox\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from datetime import datetime \n","from tqdm.notebook import tqdm \n","import statistics\n","from math import log10\n","import struct\n","from random import randrange\n","import multiprocessing\n","import concurrent.futures\n","import time\n","import torch.utils.data as data_utils\n","\n","\n","\n","path = '../dataset/dataset_purchase.tgz'\n","df = pd.read_csv(path, compression='gzip',  header=0, error_bad_lines=False)\n","# 1st column is the 'label' in this dataset\n","df = df.dropna() # drop NaN values\n","\n","#100 labels are arranged as [0,1,...,99]\n","df[df.columns[0]] = df[df.columns[0]] - 1\n","\n","df = df.astype(int)\n","df.dtypes\n","\n","# split df into train(60%), test(40%)\n","df_train, df_test = np.split(df, [int(0.60*len(df))])\n","print(df_train.shape, df_test.shape, f'{len(df_train)/(len(df_train)+len(df_test)):0.2f}')\n","\n","\n","\n","#separating label from data and converting dataframe into Torch Tensor\n","col_0 = df_train.columns[0] # 1st column is label; \n","col_rest = df_train.columns[1:] # rests are data\n","X_train = torch.tensor(df_train[col_rest].values, dtype=torch.float32) \n","y_train = torch.tensor(df_train[col_0].values) # y is row vector here\n","\n","# X_train = torch.tensor(df_train[col_rest].values) \n","# y_train = torch.tensor(df_train[col_0].values) # y is row vector here\n","\n","\n","\n","col_0 = df_test.columns[0]\n","col_rest = df_test.columns[1:]\n","X_test = torch.tensor(df_test[col_rest].values, dtype=torch.float32)\n","y_test = torch.tensor(df_test[col_0].values) # y is row vector here\n","# X_test = torch.tensor(df_test[col_rest].values)\n","# y_test = torch.tensor(df_test[col_0].values) # y is row vector here\n","\n","\n","# # convert label from one 'row' into one column \n","# y_train = y_train.view(y_train.shape[0], 1)\n","# y_test = y_test.view(y_test.shape[0], 1)\n","\n","print(f'-'*30, 'train', f'-'*30)\n","display(X_train.size(), y_train.size())\n","display(X_train, y_train)\n","\n","print(f'-'*30, 'test', f'-'*30)\n","display( X_test.size(), y_test.size())\n","display(X_test, y_test)\n","\n","\n","BATCH_SIZE = 100\n","\n","train = data_utils.TensorDataset(X_train, y_train)\n","train_loader = data_utils.DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n","\n","test = data_utils.TensorDataset(X_test, y_test)\n","valid_loader = data_utils.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(len(train_loader.dataset), len(valid_loader.dataset))\n","\n","\n","for batch_idx, (X, y_true) in enumerate(train_loader):\n","  # print(batch_idx, X.size(), y_true.size())\n","    if (batch_idx == 0):\n","        print(X)\n","        print(y_true)\n","        print(X.dtype, y_true.dtype)\n","        break\n","\n","\n","\n","def get_accuracy(model, data_loader):\n","    '''\n","    Function for computing the accuracy of the predictions over the entire data_loader\n","    '''\n","    \n","    correct_pred = 0 \n","    n = 0\n","    \n","    with torch.no_grad():\n","        model.eval()\n","        for X, y_true in data_loader:\n","\n","            y_hat = model(X)\n","            _, predicted_labels = torch.max(y_hat, 1)\n","\n","            n += y_true.size(0)\n","            correct_pred += (predicted_labels == y_true).sum()\n","\n","    return correct_pred.float() / n\n","\n","\n","\n","# PurchaseClassifier model\n","\n","class PurchaseClassifier(nn.Module):\n","\n","    def __init__(self, num_features = 600, num_classes=100):\n","        super(PurchaseClassifier, self).__init__() \n","        self.fc1 = nn.Linear(num_features,1024)\n","        self.fc2 = nn.Linear(1024,512)\n","        self.fc3 = nn.Linear(512,256)\n","        self.fc4 = nn.Linear(256,128)\n","        self.fc5 = nn.Linear(128,num_classes)\n","        self.relu = nn.Tanh()\n","\n","    def forward(self, x):\n","       #classifier\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x) \n","        x = self.relu(x)\n","        x = self.fc3(x) \n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        x = self.relu(x)\n","\n","        x = self.fc5(x)\n","\n","        # #sigmoid returns a value between 0 and 1, used for binary classification\n","        # prob = torch.sigmoid(x)   \n","        \n","        logits = x\n","        return logits\n","\n","\n","\n","RANDOM_SEED = 42\n","\n","torch.manual_seed(RANDOM_SEED)\n","target_model = PurchaseClassifier()\n","optimizer = torch.optim.Adam(target_model.parameters(), lr=0.0005)\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","\n","N_EPOCHS = 475\n","print_every = 10\n","\n","\n","\n","for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","\n","    if epoch == 20:\n","        optimizer = torch.optim.Adam(target_model.parameters(), lr=0.0005) \n","        print(\"\\nlearning rate decay to 1/10...\")\n","    if epoch == 40:\n","        optimizer = torch.optim.Adam(target_model.parameters(), lr=0.0001) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    if epoch == 60:\n","        optimizer = torch.optim.Adam(target_model.parameters(), lr=0.00005) \n","        print(\"\\nlearning rate decay to 1/10...\")\n","    if epoch == 80:\n","        optimizer = torch.optim.Adam(target_model.parameters(), lr=0.00001) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    if epoch == 100:\n","        optimizer = torch.optim.Adam(target_model.parameters(), lr=0.000005) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    for data in train_loader:\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0], data[1]\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        output = target_model(inputs)\n","\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        #parameter update\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","     \n","    # print statistics\n","    if epoch % print_every == (print_every - 1):\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","        f'Epoch: {epoch+1}\\t'\n","        f'Train loss: {epoch_loss:.4f}\\t')\n","\n","print(f'-'*30, 'training is done', f'-'*30)\n","valid_acc = get_accuracy(target_model, valid_loader)\n","print(f'Valid accuracy: {100 * valid_acc:.2f}')\n","\n","print('Finished Training.')\n","\n","\n","filename = '../dataset/Customer100.pth'\n","torch.save(target_model.state_dict(), filename)"]}]}