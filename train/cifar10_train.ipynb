{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["da0688c70b3c420c9b99ee2fe3a56132"]},"executionInfo":{"elapsed":1789601,"status":"error","timestamp":1661608643085,"user":{"displayName":"CAMLSec Lab","userId":"04365141552330932843"},"user_tz":240},"id":"dqySKJDv0zOB","outputId":"7f227138-125b-4afe-db79-54f4a76835ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting foolbox\n","  Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 17.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from foolbox) (4.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from foolbox) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from foolbox) (57.4.0)\n","Collecting requests>=2.24.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n","\u001b[?25hCollecting eagerpy>=0.30.0\n","  Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n","Collecting GitPython>=3.0.7\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 73.1 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2022.6.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (1.24.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->foolbox) (2.1.0)\n","Installing collected packages: smmap, gitdb, requests, GitPython, eagerpy, foolbox\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","Successfully installed GitPython-3.1.27 eagerpy-0.30.0 foolbox-3.3.3 gitdb-4.0.9 requests-2.28.1 smmap-5.0.0\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10_data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da0688c70b3c420c9b99ee2fe3a56132","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting cifar10_data/cifar-10-python.tar.gz to cifar10_data\n","Files already downloaded and verified\n","cpu\n","16:38:28 --- Epoch: 10\tTrain loss: 0.3786\tValid accuracy: 80.89\n","20:14:08 --- Epoch: 20\tTrain loss: 0.2371\tValid accuracy: 80.96\n","23:52:13 --- Epoch: 30\tTrain loss: 0.1907\tValid accuracy: 78.75\n","\n","learning rate decay to 1/10...\n","03:32:22 --- Epoch: 40\tTrain loss: 0.0576\tValid accuracy: 84.33\n","\n","learning rate decay to 1/100...\n","07:15:57 --- Epoch: 50\tTrain loss: 0.0045\tValid accuracy: 86.71\n","\n","learning rate decay to 1/10...\n","10:58:36 --- Epoch: 60\tTrain loss: 0.0049\tValid accuracy: 86.50\n","\n","learning rate decay to 1/100...\n"]}],"source":["\n","!pip install foolbox\n","import foolbox as fb\n","from google.colab import files\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from datetime import datetime \n","from tqdm.notebook import tqdm \n","import statistics\n","\n","# parameters\n","RANDOM_SEED = 42\n","BATCH_SIZE = 100\n","N_EPOCHS = 475\n","IMG_SIZE = 32\n","N_CLASSES = 10\n","\n","LEARNING_RATE = 0.001\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-3\n","\n","\n","# define transforms\n","# transforms.ToTensor() automatically scales the images to [0,1] range\n","# transforms = transforms.Compose([transforms.Resize((32, 32)), transforms.Normalize(mean=[0.485, 0.456, 0.406], \n","#                                 std=[0.229, 0.224, 0.225])], transforms.ToTensor()])\n","\n","transforms = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","# transforms = transforms.Compose([\n","#     transforms.Resize(256),\n","#     transforms.CenterCrop(224),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","# ])\n","\n","# download and create datasets\n","train_dataset = datasets.CIFAR10(root='cifar10_data', train=True, transform=transforms, download=True)\n","\n","valid_dataset = datasets.CIFAR10(root='cifar10_data', train=False, transform=transforms, download=True)\n","\n","# define the data loaders\n","train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","#Class labels\n","classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n","\n","\n","#implementing AlexNet_Exact model\n","class AlexNet_Exact(nn.Module):\n","\n","    def __init__(self):\n","        super(AlexNet_Exact, self).__init__()        \n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(2,2))\n","        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=(3,3), stride=(1,1), padding=(2,2))\n","        self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","                \n","        self.dropout = nn.Dropout()\n","        self.linear1 = nn.Linear(in_features = 256 * 6 * 6, out_features = 1024)\n","        self.linear2 = nn.Linear(in_features = 1024, out_features = 1024)\n","        self.linear3 = nn.Linear(in_features = 1024, out_features = 10)\n","        \n","        \n","    def forward(self, x):\n","        # Feature extractor\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","\n","        x = self.conv3(x)\n","        x = self.relu(x)\n","\n","        x = self.conv4(x)\n","        x = self.relu(x)\n","\n","        x = self.conv5(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        \n","        x = self.avgpool(x)\n","        \n","        x = x.view(x.size(0), 256 * 6 * 6)\n","        \n","        x = self.dropout(x)\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        \n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        x = self.relu(x)\n","        \n","        logits = self.linear3(x)\n","#         probs = F.softmax(logits, dim=1)\n","        \n","        return logits\n","\n","\n","\n","torch.manual_seed(RANDOM_SEED)\n","model_exact = AlexNet_Exact()\n","optimizer = torch.optim.SGD(model_exact.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","criterion = nn.CrossEntropyLoss()\n","\n","# Train model \n","# model_exact, optimizer, _ = training_loop(model_exact, criterion, optimizer, train_loader, valid_loader, N_EPOCHS)\n","\n","\n","\n","#Instantiating CUDA device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","#Verifying CUDA\n","print(device)\n","#Move the input and AlexNet_model to GPU for speed if available\n","model_exact.to(device)\n","\n","#Testing Accuracy\n","def get_accuracy(model, data_loader, device):\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in data_loader:\n","          images, labels = data[0].to(device), data[1].to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy = (correct / total)\n","  return accuracy\n","\n","print_every = 10\n","for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","\n","    if epoch == 30:\n","        optimizer = torch.optim.SGD(model_exact.parameters(), lr=0.0005, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","        print(\"\\nlearning rate decay to 1/10...\")\n","    if epoch == 40:\n","        optimizer = torch.optim.SGD(model_exact.parameters(), lr=0.0001, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    if epoch == 50:\n","        optimizer = torch.optim.SGD(model_exact.parameters(), lr=0.00005, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","        print(\"\\nlearning rate decay to 1/10...\")\n","    if epoch == 60:\n","        optimizer = torch.optim.SGD(model_exact.parameters(), lr=0.00001, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    if epoch == 70:\n","        optimizer = torch.optim.SGD(model_exact.parameters(), lr=0.000005, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) \n","        print(\"\\nlearning rate decay to 1/100...\")\n","\n","    for i, data in enumerate(train_loader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        output = model_exact(inputs)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item() * inputs.size(0)\n","    \n","    if epoch % print_every == (print_every - 1):\n","      epoch_loss = running_loss / len(train_loader.dataset)\n","      valid_acc = get_accuracy(model_exact, valid_loader, device)\n","      print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","      f'Epoch: {epoch+1}\\t'\n","      f'Train loss: {epoch_loss:.4f}\\t'\n","      f'Valid accuracy: {100 * valid_acc:.2f}')\n","\n","\n","print('Finished Training of AlexNet')\n","\n","\n","filename = '../dataset/Cifar10.pth'\n","torch.save(model_exact.state_dict(), filename)\n"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","machine_shape":"hm","provenance":[],"collapsed_sections":[],"mount_file_id":"1JN8xnbIGQPg71TDBlb6780VyB-3tn1H1","authorship_tag":"ABX9TyMkT3e8l1kEcxkIcPKLz9yr"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}