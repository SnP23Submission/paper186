{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":[],"authorship_tag":"ABX9TyPCtTTgBYQpMPrDaeUkp3Ih"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"L2TCqqnVAc3n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642800387116,"user_tz":300,"elapsed":17910,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"2f487258-6833-4f21-975a-92eb6c0373d4"},"source":["!pip install adversarial-robustness-toolbox\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from datetime import datetime \n","from tqdm.notebook import tqdm \n","import statistics\n","from math import log10\n","import struct\n","from random import randrange\n","import multiprocessing\n","import concurrent.futures\n","import time\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n","from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n","import joblib \n","\n","fr_global = 100"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.9.1-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.9 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n","Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n","Collecting numba>=0.53.1\n","  Downloading numba-0.55.0-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 51.1 MB/s \n","\u001b[?25hCollecting llvmlite<0.39,>=0.38.0rc1\n","  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[K     |████████████████████████████████| 34.5 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.0.0)\n","Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","Successfully installed adversarial-robustness-toolbox-1.9.1 llvmlite-0.38.0 numba-0.55.0\n"]}]},{"cell_type":"code","metadata":{"id":"u8s2hKW6-tPU"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Di38lmUr9dXp","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1642800392319,"user_tz":300,"elapsed":1658,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"8fa04104-b2f6-4b4a-fee1-2d4c8e841284"},"source":["train_size = 10000\n","\n","filename = '../dataset/purchase_member.csv'\n","# filename = '/content/purchase_member.csv'\n","df_train = pd.read_csv (filename, header=None,   sep='\\t', encoding='utf-8') \n","\n","filename = '../dataset/purchase_non_member.csv'\n","# filename = '/content/purchase_non_member.csv'\n","df_test = pd.read_csv (filename,  header=None,  sep='\\t', encoding='utf-8') \n","\n","print(df_train.shape, df_test.shape, f'{len(df_train)/(len(df_train)+len(df_test)):0.2f}')\n","\n","\n","#separating label from data and converting dataframe into Torch Tensor\n","col_0 = df_train.columns[0] # 1st column is label; \n","col_rest = df_train.columns[1:] # rests are data\n","X_train = torch.tensor(df_train[col_rest].values, dtype=torch.float32) \n","y_train = torch.tensor(df_train[col_0].values) # y is row vector here\n","\n","print(f'-'*30, 'train', f'-'*30)\n","display(X_train.size(), y_train.size())\n","display(X_train, y_train)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 601) (32254, 601) 0.24\n","------------------------------ train ------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["torch.Size([10000, 600])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["torch.Size([10000])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 1., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 1., 0.,  ..., 0., 0., 0.],\n","        [0., 1., 0.,  ..., 1., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([54, 36, 97,  ..., 97, 71,  7])"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"yrqLAuVNhcP6"},"source":["'''\n","Approximate model ...\n","'''\n","\n","# any element(float point) of tensor is represented by 32 bits\n","def fault_injection_FP(dec_list):\n","    \n","    fault_rate = fr_global\n","    \n","    output_list = []\n","    \n","    for dec in dec_list:\n","\n","        a = ''.join(bin(c).replace('0b', '').rjust(8, '0') for c in struct.pack('!f', dec))        \n","\n","        #generate 32-bit binary mask for given fault rate\n","        mask_bin = []\n","        #Keep the most significant bit (sign bit) and 5 least significant bits unchanged\n","        mask_bin = ['0'] + ['1' if randrange(1000000) < fault_rate else '0' for i in range(26)] + ['0' for i in range(5)]    \n","\n","        a_faulty = list('00000000000000000000000000000000')\n","        a_bin = list(a)\n","        for i in range(32):\n","            a_faulty[i] = str(int(a_bin[i])^int(mask_bin[i])) \n","        aa = ''.join(a_faulty) \n","        f = struct.unpack('!f',struct.pack('!I', int(aa, 2)))[0]\n","        \n","        output_list.append(f)\n","    \n","    return output_list\n","          \n","\n","def fault_injection_FC_layer(x, layer, status):   \n","    \n","    #set fault_rate = 0 during train time.\n","    #set fault_rates = 1, 10, 100, 1000, 10000, 100000, 1000000, one by one, during test time\n","    #these fault rates corresponse to actual fault rate of 10^-6, 10^-5, 10^-4, 10^-3, 10^-2, 10^-1, 10^-0 \n","    #----------------------------------------------------------------------------------------------------\n","    fault_rate = fr_global\n","    \n","    if (status == 'ON'):\n","      # print(f'\\tfault_rate = {fault_rate/1000000:.0e};   {layer} is {status}')\n","\n","      x_dim = list(x.size())\n","      n_row = x_dim[0]\n","      n_column = x_dim[1]\n","      \n","      x_list = [element.item() for element in x.flatten()]\n","\n","      n_process = multiprocessing.cpu_count()\n","      k, m = divmod(len(x_list), n_process)\n","      x_list_sublist = list((x_list[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n_process)))\n","\n","      with concurrent.futures.ProcessPoolExecutor() as executor:\n","          output_list_sublist = executor.map(fault_injection_FP, x_list_sublist)\n","\n","      output_flat_list = [item for sublist in output_list_sublist for item in sublist] \n","\n","      shape = (n_row, n_column)\n","      output_array = np.array(output_flat_list)\n","      output_array = output_array.reshape(shape )\n","\n","      output_tensor = torch.from_numpy(output_array).float()\n","      x.data = output_tensor.data\n"," \n","    return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9F7EUtmhc33"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wAAnk3jR4n-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642800400431,"user_tz":300,"elapsed":202,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"d398d16a-fe21-430a-dd06-0fce6d18a171"},"source":["\n","# PurchaseClassifier_Approx model\n","\n","class PurchaseClassifier_Approx(nn.Module):\n","\n","    def __init__(self, num_features = 600, num_classes=100):\n","        super(PurchaseClassifier_Approx, self).__init__() \n","        self.fc1 = nn.Linear(num_features,1024)\n","        self.fc2 = nn.Linear(1024,512)\n","        self.fc3 = nn.Linear(512,256)\n","        self.fc4 = nn.Linear(256,128)\n","        self.fc5 = nn.Linear(128,num_classes)\n","        self.relu = nn.Tanh()\n","\n","    def forward(self, x):\n","       #classifier\n","        x = self.fc1(x)\n","        x = fault_injection_FC_layer(x, layer='FC-1', status='ON')\n","        x = self.relu(x)\n","\n","        x = self.fc2(x)\n","        x = fault_injection_FC_layer(x, layer='FC-2', status='ON') \n","        x = self.relu(x)\n","\n","        x = self.fc3(x) \n","        x = fault_injection_FC_layer(x, layer='FC-3', status='ON')\n","        x = self.relu(x)\n","\n","        x = self.fc4(x)\n","        # x = fault_injection_FC_layer(x, layer='FC-4', status='ON')\n","        x = self.relu(x)\n","\n","        x = self.fc5(x)\n","\n","        # #sigmoid returns a value between 0 and 1, used for binary classification\n","        # prob = torch.sigmoid(x)   \n","        \n","        logits = x\n","        return logits\n","\n","\n","\n","\n","target_model_vos = PurchaseClassifier_Approx()\n","\n","model_path = '../dataset/Customer100_10k_train.pth'\n","# model_path = '/content/Customer100_10k_train.pth'\n","target_model_vos.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","target_model_vos.eval()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PurchaseClassifier_Approx(\n","  (fc1): Linear(in_features=600, out_features=1024, bias=True)\n","  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=256, bias=True)\n","  (fc4): Linear(in_features=256, out_features=100, bias=True)\n","  (relu): Tanh()\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"IpffhVmkivCJ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","epoch = [500]\n","exetime = []\n","fr_global = 1\n","\n","print(f'\\tfault_rate = {fr_global/10000000:.0e}...')\n","\n","one_sample = torch.tensor(df_train.head(1)[col_rest].values, dtype=torch.float32) \n","\n","for e in epoch:\n","  start_time = time.time()\n","  for i in range(e):\n","    _ = target_model_vos(one_sample)\n","\n","  time_one_sample = (time.time() - start_time)*1000000\n","  exetime.append(time_one_sample)\n","\n","print(f\"One inference time: --- {exetime} microseconds\")\n","\n"," \n"," "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86pAaUqW9gFx","executionInfo":{"status":"ok","timestamp":1642801474307,"user_tz":300,"elapsed":116065,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"e0e239fa-70eb-400a-cb72-5ed6678c6e57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\tfault_rate = 1e-07...\n","One inference time: --- [115805553.67469788] microseconds\n"]}]},{"cell_type":"code","source":["t = [f'& {round(t/1000000, 2)} &' for t in exetime]\n","print(t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR-1lCET9hFW","executionInfo":{"status":"ok","timestamp":1642747008032,"user_tz":300,"elapsed":411,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"7aff6e66-5036-412a-d2e7-46787bd67fd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['& 0.55 &', '& 10.7 &', '& 21.24 &', '& 32.03 &', '& 42.96 &', '& 54.53 &', '& 283.94 &']\n"]}]},{"cell_type":"code","metadata":{"id":"O-lDNUBdiuOV"},"source":["def get_accuracy(model, data_loader):\n","    '''\n","    Function for computing the accuracy of the predictions over the entire data_loader\n","    '''\n","    \n","    correct_pred = 0 \n","    n = 0\n","    \n","    with torch.no_grad():\n","        model.eval()\n","        for X, y_true in data_loader:\n","\n","            y_hat = model(X)\n","            _, predicted_labels = torch.max(y_hat, 1)\n","\n","            n += y_true.size(0)\n","            correct_pred += (predicted_labels == y_true).sum()\n","\n","    return correct_pred.float() / n\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RPkgiEcJb3m"},"source":["\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENLFbQKr1z3n"},"source":["'''\n","MIA with Logit\n","'''\n","\n","def mia_with_logit(y_hat):\n","\n","  df_logit = pd.DataFrame(y_hat.detach().numpy())\n","  scaler = StandardScaler() #94 70\n","  df_logit  = pd.DataFrame(scaler.fit_transform(df_logit))\n","  df_logit = df_logit.fillna(0)\n","\n","  y_test2_np = np.array([int(1) for i in range(len(df_logit))]) \n","\n","  n_feature = len(df_logit.columns) \n","  attacker_mlp_logit = MLPClassifier(hidden_layer_sizes=(n_feature, n_feature, 50, 25), activation='relu', max_iter = 2000, random_state = 1)\n","  attacker_mlp_logit = joblib.load('../dataset/attacker_mlp_logit.pkl')\n","\n","  y_pred_np = attacker_mlp_logit.predict(df_logit)\n","  accuracy  = round(np.mean(y_pred_np == y_test2_np), 2)\n","  # print(f'MIA with Logit: {accuracy}')\n","  return accuracy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHvDj5oC10Q1"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbNK_QXD10oH"},"source":["'''\n","MIA with Probability \n","'''\n","\n","def mia_with_probability(y_hat):\n","\n","  logit = y_hat\n","  X_mem_prob = torch.sigmoid(logit)\n","  X_test_attacker_df = pd.DataFrame(X_mem_prob.detach().numpy())\n","\n","  scaler = StandardScaler() #94 70\n","  X_test_attacker_df  = pd.DataFrame(scaler.fit_transform(X_test_attacker_df))\n","  X_test_attacker_df = X_test_attacker_df.fillna(0)\n","\n","  y_test2_np = np.array([int(1) for i in range(len(X_test_attacker_df))]) \n","\n","  n_feature = len(X_test_attacker_df.columns) \n","  attacker_mlp_prob = MLPClassifier(hidden_layer_sizes=(n_feature, n_feature, 50, 25), activation='relu', max_iter = 2000, random_state = 1)\n","  attacker_mlp_prob = joblib.load('../dataset/attacker_mlp_prob.pkl')\n","\n","  y_pred_np = attacker_mlp_prob.predict(X_test_attacker_df)\n","  accuracy  = round(np.mean(y_pred_np == y_test2_np), 2)\n","  # print(f'MIA with Probability:  {accuracy}')\n","  return accuracy\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xaL9ib_0sahc"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6ijNrtF11Dl"},"source":["'''\n","MIA with Probability & Loss\n","\n","'''\n","\n","def myCustomLoss(my_outputs, my_labels):\n","  #specifying the batch size\n","  my_batch_size = my_outputs.size()[0] \n","  #calculating the log of softmax values           \n","  my_outputs = F.log_softmax(my_outputs, dim=1)  \n","  #selecting the values that correspond to labels\n","  my_outputs = my_outputs[range(my_batch_size), my_labels] \n","  #returning the results\n","  return my_outputs\n","\n","def mia_with_probability_loss(y_hat, y_test):\n","\n","  logit = y_hat\n","  X_mem_nonmem_prob = torch.sigmoid(logit)\n","  df_tmp = pd.DataFrame(X_mem_nonmem_prob.detach().numpy())\n","\n","  loss = myCustomLoss(logit, y_test)\n","  df_loss = pd.DataFrame(loss.detach().numpy())\n","  # scaler = StandardScaler() #94 70\n","  scaler = RobustScaler() #94 70\n","  df_loss  = pd.DataFrame(scaler.fit_transform(df_loss))\n","\n","  X_test_attacker_df = pd.concat([df_tmp, df_loss], ignore_index=True, axis=1) #axis=1 merges 2 dataframes side by side\n","  X_test_attacker_df = X_test_attacker_df.fillna(0)\n","\n","  y_test2_np = np.array([int(1) for i in range(len(X_test_attacker_df))]) \n","\n","  n_feature = len(X_test_attacker_df.columns) \n","  attacker_mlp_prob_loss = MLPClassifier(hidden_layer_sizes=(n_feature, n_feature, 50, 25), activation='relu', max_iter = 2000, random_state = 1)\n","  attacker_mlp_prob_loss = joblib.load('../dataset/attacker_mlp_prob_loss.pkl')\n","\n","  y_pred_np = attacker_mlp_prob_loss.predict(X_test_attacker_df)\n","  accuracy  = round(np.mean(y_pred_np == y_test2_np), 2)\n","  # print(f'MIA with Probability & Loss:  {accuracy}')\n","  return accuracy\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JaXcfltP9c3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6ddUKigwAj_"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNMumBtLv_zB","executionInfo":{"status":"ok","timestamp":1636047320177,"user_tz":240,"elapsed":6954295,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"bb464417-4b55-464b-afd9-f045b7d2c27a"},"source":["'''\n","Target Model Test accuracy\n","'''\n","#separating label from data and converting dataframe into Torch Tensor\n","col_0 = df_test.columns[0] # 1st column is label; \n","col_rest = df_test.columns[1:] # rests are data\n","X_test = torch.tensor(df_test.head(5000)[col_rest].values, dtype=torch.float32) \n","y_test = torch.tensor(df_test.head(5000)[col_0].values) # y is row vector here\n","\n","print(f'-'*30, 'test', f'-'*30)\n","\n","\n","baseline_acc_mean = [] # target model test accuracy under VOS\n","baseline_acc_std = []\n","\n","MIA_logit_mean = []\n","MIA_logit_std = []\n","\n","MIA_prob_mean = []\n","MIA_prob_std = []\n","\n","MIA_prob_loss_mean = []\n","MIA_prob_loss_std = []\n","\n","fault_rates = [1, 10, 100, 1000]\n","\n","for fr in fault_rates:\n","\n","  fr_global = fr\n","\n","  print(f'\\tfault_rate = {fr_global/1000000:.0e}...')\n","  print(f'-'*60)\n","\n","  baseline_tmp = []\n","  MIA_logit_tmp = []\n","  MIA_prob_tmp = []\n","  MIA_prob_loss_tmp = []\n","\n","  for i in range(50):\n","    y_hat = target_model_vos(X_test)\n","    _, predicted_labels = torch.max(y_hat, 1)\n","    n = y_test.size(0)\n","    correct_pred = (predicted_labels == y_test).sum()\n","    test_acc = correct_pred.float() / n\n","    test_acc  = round(test_acc.item(), 2)\n","\n","    baseline_tmp.append(test_acc)\n","    MIA_logit_tmp.append(mia_with_logit(y_hat))\n","    MIA_prob_tmp.append(mia_with_probability(y_hat))\n","    MIA_prob_loss_tmp.append(mia_with_probability_loss(y_hat, y_test))\n","\n","  baseline_acc_mean.append(statistics.mean(baseline_tmp))\n","  baseline_acc_std.append(statistics.stdev(baseline_tmp))\n","\n","  MIA_logit_mean.append(statistics.mean(MIA_logit_tmp))\n","  MIA_logit_std.append(statistics.stdev(MIA_logit_tmp))\n","\n","  MIA_prob_mean.append(statistics.mean(MIA_prob_tmp))\n","  MIA_prob_std.append(statistics.stdev(MIA_prob_tmp))\n","\n","  MIA_prob_loss_mean.append(statistics.mean(MIA_prob_loss_tmp))\n","  MIA_prob_loss_std.append(statistics.stdev(MIA_prob_loss_tmp))\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------ test ------------------------------\n","\tfault_rate = 1e-06...\n","------------------------------------------------------------\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-06;   FC-1 is ON\n","\tfault_rate = 1e-06;   FC-2 is ON\n","\tfault_rate = 1e-06;   FC-3 is ON\n","\tfault_rate = 1e-05...\n","------------------------------------------------------------\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-05;   FC-1 is ON\n","\tfault_rate = 1e-05;   FC-2 is ON\n","\tfault_rate = 1e-05;   FC-3 is ON\n","\tfault_rate = 1e-04...\n","------------------------------------------------------------\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-04;   FC-1 is ON\n","\tfault_rate = 1e-04;   FC-2 is ON\n","\tfault_rate = 1e-04;   FC-3 is ON\n","\tfault_rate = 1e-03...\n","------------------------------------------------------------\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n","\tfault_rate = 1e-03;   FC-1 is ON\n","\tfault_rate = 1e-03;   FC-2 is ON\n","\tfault_rate = 1e-03;   FC-3 is ON\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mI0hSXPwv_kB","executionInfo":{"status":"ok","timestamp":1636047514811,"user_tz":240,"elapsed":101,"user":{"displayName":"CAMLSec Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04365141552330932843"}},"outputId":"c790d8a2-2f83-449c-f46d-e81e81760dd2"},"source":["print(f'baseline_acc_mean: {baseline_acc_mean}')\n","print(f'baseline_acc_std: {baseline_acc_std}')\n","print()\n","\n","print(f'MIA_logit_mean: {MIA_logit_mean}')\n","print(f'MIA_logit_std: {MIA_logit_std}')\n","print()\n","\n","print(f'MIA_prob_mean: {MIA_prob_mean}')\n","print(f'MIA_prob_std: {MIA_prob_std}')\n","print()\n","\n","print(f'MIA_prob_loss_mean: {MIA_prob_loss_mean}')\n","print(f'MIA_prob_loss_std: {MIA_prob_loss_std}')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["baseline_acc_mean: [0.78, 0.77, 0.75, 0.547]\n","baseline_acc_std: [0.0, 0.0, 0.0, 0.004830458915396484]\n","\n","MIA_logit_mean: [0.35, 0.35, 0.338, 0.245]\n","MIA_logit_std: [0.0, 0.0, 0.004216370213557843, 0.0052704627669473035]\n","\n","MIA_prob_mean: [0.14, 0.14, 0.166, 0.393]\n","MIA_prob_std: [0.0, 0.0, 0.005163977794943227, 0.004830458915396484]\n","\n","MIA_prob_loss_mean: [0.36, 0.36, 0.383, 0.555]\n","MIA_prob_loss_std: [0.0, 0.0, 0.004830458915396484, 0.0052704627669473035]\n"]}]},{"cell_type":"code","metadata":{"id":"NTuCiAcp_v1c"},"source":[],"execution_count":null,"outputs":[]}]}